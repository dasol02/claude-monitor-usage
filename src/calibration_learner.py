#!/usr/bin/env python3
"""
Calibration Learner v2 - Per-session window calibration

ê°œì„ ì‚¬í•­:
1. ë§¤ë²ˆ ëª¨ë‹ˆí„° ì²´í¬ì‹œ ìë™ ë³´ì • (ì‚¬ìš©ì ì…ë ¥ ë°›ìŒ)
2. ì„¸ì…˜ ìœˆë„ìš°ë³„ ë…ë¦½ì  í•™ìŠµ (15:00-20:00, 20:00-01:00 ë“±)
3. ë¦¬ì…‹ íƒ€ì„ ê³ ë ¤ - ì„¸ì…˜ ë°”ë€Œë©´ í•´ë‹¹ ìœˆë„ìš° ë°ì´í„°ë§Œ ì‚¬ìš©
"""

import json
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import Dict, Optional, Tuple


# íŒŒì¼ ê²½ë¡œ
CALIBRATION_DATA_FILE = Path.home() / '.claude-monitor' / 'calibration_data.json'
BASELINE_THRESHOLD = 0.15  # ì´ˆê¸° baseline
MIN_LEARNED_LIMIT = 100  # TPM ìµœì†Œê°’
MAX_LEARNED_LIMIT = 20000  # TPM ìµœëŒ€ê°’


def load_session_config():
    """Configì—ì„œ ì„¸ì…˜ ì„¤ì • ì½ê¸°"""
    from pathlib import Path
    config_file = Path.home() / '.claude-monitor' / 'config.json'

    if not config_file.exists():
        return 14  # ê¸°ë³¸ê°’

    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
        return config.get('reset_schedule', {}).get('session_base_hour', 14)
    except:
        return 14


def get_session_window_key(now: datetime) -> str:
    """
    í˜„ì¬ ì‹œê°„ì´ ì†í•œ ì„¸ì…˜ ìœˆë„ìš° í‚¤ ë°˜í™˜ (config ê¸°ë°˜)

    Returns:
        str: 'HH:MM-HH:MM' í˜•ì‹ (ì˜ˆ: '14:00-19:00')
    """
    base_hour = load_session_config()
    hour = now.hour

    # Base hourë¥¼ ê¸°ì¤€ìœ¼ë¡œ 5ê°œì˜ 5ì‹œê°„ ìœˆë„ìš° ìƒì„±
    windows = []
    current_start = base_hour
    for _ in range(5):
        current_end = (current_start + 5) % 24
        windows.append((current_start, current_end))
        current_start = current_end

    # í˜„ì¬ ì‹œê°„ì´ ì†í•œ ìœˆë„ìš° ì°¾ê¸°
    for win_start, win_end in windows:
        if win_end < win_start:  # ìì •ì„ ë„˜ì–´ê°€ëŠ” ê²½ìš°
            if hour >= win_start or hour < win_end:
                return f"{win_start:02d}:00-{win_end:02d}:00"
        else:  # ê°™ì€ ë‚  ë‚´
            if win_start <= hour < win_end:
                return f"{win_start:02d}:00-{win_end:02d}:00"

    # ê¸°ë³¸ê°’
    return f"{base_hour:02d}:00-{(base_hour + 5) % 24:02d}:00"


def get_weekly_window_key() -> str:
    """
    ì£¼ê°„ ìœˆë„ìš° í‚¤ ë°˜í™˜ (í•­ìƒ ê³ ì •)

    Returns:
        str: 'weekly'
    """
    return "weekly"


def get_window_end_time(window_key: str) -> datetime:
    """
    ìœˆë„ìš° ì¢…ë£Œ ì‹œê°„ ê³„ì‚° (window_key íŒŒì‹±)

    Args:
        window_key: 'HH:MM-HH:MM' í˜•ì‹ (ì˜ˆ: '14:00-19:00') ë˜ëŠ” 'weekly'

    Returns:
        datetime: ìœˆë„ìš° ì¢…ë£Œ ì‹œê°„
    """
    from datetime import timedelta

    tz = ZoneInfo('Asia/Seoul')
    now = datetime.now(tz)

    # ì£¼ê°„ ìœˆë„ìš°ëŠ” 7ì¼ í›„ë¡œ ì„¤ì •
    if window_key == "weekly":
        return now + timedelta(days=7)

    # window_key íŒŒì‹± (ì˜ˆ: '14:00-19:00' â†’ end_hour = 19)
    try:
        parts = window_key.split('-')
        end_time_str = parts[1]  # '19:00'
        end_hour = int(end_time_str.split(':')[0])
    except:
        end_hour = 19  # ê¸°ë³¸ê°’

    # ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
    if end_hour == 0:
        # ìì •ì¸ ê²½ìš°
        if now.hour >= 12:
            # í˜„ì¬ê°€ ì˜¤í›„/ë°¤ì´ë©´ ë‹¤ìŒë‚  00ì‹œ
            window_end = (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
        else:
            # í˜„ì¬ê°€ ìƒˆë²½ì´ë©´ ì˜¤ëŠ˜ 00ì‹œ
            window_end = now.replace(hour=0, minute=0, second=0, microsecond=0)
    elif end_hour < now.hour:
        # ì¢…ë£Œ ì‹œê°„ì´ í˜„ì¬ë³´ë‹¤ ì´ì „ì´ë©´ ì˜¤ëŠ˜ (ì„¸ì…˜ ì§„í–‰ ì¤‘)
        window_end = now.replace(hour=end_hour, minute=0, second=0, microsecond=0)
    else:
        # ì¢…ë£Œ ì‹œê°„ì´ í˜„ì¬ë³´ë‹¤ ì´í›„ë©´ ì˜¤ëŠ˜
        window_end = now.replace(hour=end_hour, minute=0, second=0, microsecond=0)

    return window_end


def reverse_calculate_limit(actual_percentage: float, current_tokens: int, window_minutes: int = 300) -> Optional[int]:
    """
    ì‹¤ì œ í¼ì„¼íŠ¸ì™€ í˜„ì¬ í† í°ìœ¼ë¡œ limit ì—­ì‚°

    Args:
        actual_percentage: ì‹¤ì œ í¼ì„¼íŠ¸ (0-100)
        current_tokens: í˜„ì¬ í† í° ì‚¬ìš©ëŸ‰
        window_minutes: ìœˆë„ìš° ì‹œê°„(ë¶„) (ê¸°ë³¸: 300ë¶„ = 5ì‹œê°„)

    Returns:
        int: TPM (tokens per minute) ë˜ëŠ” None

    ì˜ˆì‹œ:
        actual = 39%, tokens = 103,279, window = 300ë¶„
        â†’ limit = 103,279 / 0.39 / 300 = 882 TPM
    """
    if actual_percentage <= 0 or current_tokens <= 0:
        return None

    limit_per_minute = current_tokens / (actual_percentage / 100) / window_minutes
    limit_rounded = round(limit_per_minute)

    # ë²”ìœ„ ê²€ì¦
    if limit_rounded < MIN_LEARNED_LIMIT:
        print(f"âš ï¸  Warning: Calculated limit ({limit_rounded} TPM) too low, using minimum ({MIN_LEARNED_LIMIT} TPM)")
        return MIN_LEARNED_LIMIT
    elif limit_rounded > MAX_LEARNED_LIMIT:
        print(f"âš ï¸  Warning: Calculated limit ({limit_rounded} TPM) too high, using maximum ({MAX_LEARNED_LIMIT} TPM)")
        return MAX_LEARNED_LIMIT

    return limit_rounded


def set_calibration_override(window_key: str, calibrated_pct: float, learned_limit: int, expires_at: str):
    """
    ì„¸ì…˜ì— override ê°’ ì„¤ì • (ì¦‰ì‹œ ë°˜ì˜)

    Args:
        window_key: ì„¸ì…˜ ìœˆë„ìš° í‚¤
        calibrated_pct: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ í¼ì„¼íŠ¸ (0-100)
        learned_limit: í•™ìŠµëœ limit (TPM)
        expires_at: ë§Œë£Œ ì‹œê°„ (ISO format)
    """
    data = load_calibration_data()

    if window_key not in data:
        data[window_key] = {'history': [], 'model': None}

    data[window_key]['latest_override'] = {
        'timestamp': datetime.now(ZoneInfo('Asia/Seoul')).isoformat(),
        'calibrated_percentage': calibrated_pct,
        'expires_at': expires_at,
        'learned_limit': learned_limit
    }

    save_calibration_data(data)


def load_calibration_data() -> Dict:
    """
    ë³´ì • ë°ì´í„° ë¡œë“œ

    êµ¬ì¡°:
    {
        "15:00-20:00": {
            "history": [...],
            "model": {...}
        },
        "20:00-01:00": {...},
        ...
    }
    """
    if not CALIBRATION_DATA_FILE.exists():
        return {}

    try:
        with open(CALIBRATION_DATA_FILE, 'r') as f:
            return json.load(f)
    except:
        return {}


def save_calibration_data(data: Dict):
    """ë³´ì • ë°ì´í„° ì €ì¥"""
    CALIBRATION_DATA_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(CALIBRATION_DATA_FILE, 'w') as f:
        json.dump(data, f, indent=2)


def get_global_fallback_limit() -> Optional[int]:
    """
    ëª¨ë“  ì„¸ì…˜ì˜ learned_output_limitì„ ê°€ì¤‘ í‰ê· í•˜ì—¬ fallback limit ê³„ì‚°

    Returns:
        int: Global fallback output limit (TPM), ë°ì´í„° ì—†ìœ¼ë©´ None
    """
    data = load_calibration_data()

    limits = []
    weights = []

    # ëª¨ë“  ì„¸ì…˜ ìœˆë„ìš°ì—ì„œ learned_output_limit ìˆ˜ì§‘ (weekly ì œì™¸)
    for window_key, window_data in data.items():
        if window_key == "weekly":
            continue

        model = window_data.get('model')
        if not model:
            continue

        learned_limit = model.get('learned_output_limit')
        sample_count = model.get('sample_count', 0)

        # Learned limitì´ ìˆê³  ìƒ˜í”Œì´ 3ê°œ ì´ìƒì¸ ê²½ìš°ë§Œ ì‚¬ìš©
        if learned_limit and learned_limit > 0 and sample_count >= 3:
            limits.append(learned_limit)
            # ìƒ˜í”Œ ìˆ˜ì— ë¹„ë¡€í•œ ê°€ì¤‘ì¹˜ (ë” ë§ì€ ìƒ˜í”Œ = ë” ë†’ì€ ì‹ ë¢°ë„)
            weight = min(sample_count / 10.0, 1.0)  # ìµœëŒ€ 1.0
            weights.append(weight)

    if not limits:
        return None

    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    total_weight = sum(weights)
    weighted_avg = sum(l * w for l, w in zip(limits, weights)) / total_weight

    return round(weighted_avg)


def get_monitor_reading() -> Optional[Tuple[float, float, str, Dict]]:
    """
    í˜„ì¬ ëª¨ë‹ˆí„°ê°€ ì½ì€ ì‚¬ìš©ëŸ‰ ê°€ì ¸ì˜¤ê¸°

    Returns:
        tuple: (session_pct, weekly_pct, session_window_key, token_data) or None
    """
    output_file = Path.home() / '.claude_usage.json'

    if not output_file.exists():
        return None

    try:
        with open(output_file, 'r') as f:
            data = json.load(f)

        if data.get('status') != 'active':
            return None

        # Session & Weekly max percentage
        session_pct = data['session']['percentages']['max_percentage']
        weekly_pct = data['weekly']['percentages']['max_percentage']

        # ì„¸ì…˜ ìœˆë„ìš° ì •ë³´
        session_start_str = data['session']['window']['start']
        session_start = datetime.fromisoformat(session_start_str)
        window_key = get_session_window_key(session_start)

        # í† í° ì‚¬ìš©ëŸ‰ ë°ì´í„°
        token_data = {
            'input_tokens': data['session']['usage']['input_tokens'],
            'output_tokens': data['session']['usage']['output_tokens'],
            'cache_creation_tokens': data['session']['usage']['cache_creation_tokens'],
            'total_counted_tokens': data['session']['usage']['total_counted_tokens']
        }

        return session_pct / 100.0, weekly_pct / 100.0, window_key, token_data

    except Exception as e:
        print(f"âš ï¸  Error reading monitor output: {e}")
        return None


def record_calibration_point(window_key: str, monitor_value: float, actual_value: float, token_data: Dict = None) -> Dict:
    """
    ë³´ì • í¬ì¸íŠ¸ ê¸°ë¡ (ì„¸ì…˜ë³„)

    Args:
        window_key: ì„¸ì…˜ ìœˆë„ìš° í‚¤
        monitor_value: ëª¨ë‹ˆí„° ì½ì€ ê°’ (0.0 ~ 1.0)
        actual_value: ì‹¤ì œ ê°’ (0.0 ~ 1.0)
        token_data: í† í° ì‚¬ìš©ëŸ‰ ë°ì´í„° (optional)

    Returns:
        dict: ê¸°ë¡ëœ í¬ì¸íŠ¸
    """
    tz = ZoneInfo('Asia/Seoul')
    now = datetime.now(tz)

    offset = actual_value - monitor_value

    point = {
        'timestamp': now.isoformat(),
        'monitor_value': round(monitor_value, 4),
        'actual_value': round(actual_value, 4),
        'offset': round(offset, 4),
        'absolute_error': round(abs(offset), 4)
    }

    # í† í° ë°ì´í„° ì¶”ê°€ (limit ì—­ì‚°ìš©)
    if token_data:
        point['token_data'] = token_data

    # ë°ì´í„° ë¡œë“œ
    data = load_calibration_data()

    # í•´ë‹¹ ìœˆë„ìš° ì´ˆê¸°í™”
    if window_key not in data:
        data[window_key] = {
            'history': [],
            'model': None
        }

    # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    data[window_key]['history'].append(point)

    # ìµœëŒ€ 200ê°œê¹Œì§€ë§Œ ë³´ê´€ (ìœˆë„ìš°ë³„)
    if len(data[window_key]['history']) > 200:
        data[window_key]['history'] = data[window_key]['history'][-200:]

    save_calibration_data(data)

    return point


def update_calibration_model(window_key: str) -> Dict:
    """
    íŠ¹ì • ì„¸ì…˜ ìœˆë„ìš°ì˜ ë³´ì • ëª¨ë¸ ì—…ë°ì´íŠ¸

    Args:
        window_key: ì„¸ì…˜ ìœˆë„ìš° í‚¤

    Returns:
        dict: ì—…ë°ì´íŠ¸ëœ ëª¨ë¸
    """
    data = load_calibration_data()

    if window_key not in data:
        # ë°ì´í„° ì—†ìŒ
        return {
            'offset_mean': 0.0,
            'offset_std': 0.0,
            'confidence': 0.0,
            'sample_count': 0,
            'last_updated': None,
            'baseline_threshold': BASELINE_THRESHOLD,
            'status': 'no_data',
            'window_key': window_key
        }

    history = data[window_key]['history']

    if len(history) < 3:
        # ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ
        model = {
            'offset_mean': 0.0,
            'offset_std': 0.0,
            'confidence': 0.0,
            'sample_count': len(history),
            'last_updated': datetime.now(ZoneInfo('Asia/Seoul')).isoformat(),
            'baseline_threshold': BASELINE_THRESHOLD,
            'status': 'insufficient_data',
            'window_key': window_key
        }
        data[window_key]['model'] = model
        save_calibration_data(data)
        return model

    # ì ì‘í˜• ìƒ˜í”Œ ì„ íƒ (ì´ˆê¸°ì—ëŠ” ì ê²Œ, ë‚˜ì¤‘ì—ëŠ” ë§ì´)
    sample_count = len(history)
    if sample_count <= 10:
        # ì´ˆê¸°: ìµœê·¼ 5ê°œ (ë¹ ë¥¸ í•™ìŠµ)
        recent_history = history[-5:]
        target_samples = 10
    elif sample_count <= 30:
        # ì¤‘ê¸°: ìµœê·¼ 20ê°œ (ì•ˆì •í™”)
        recent_history = history[-20:]
        target_samples = 30
    else:
        # í›„ê¸°: ìµœê·¼ 50ê°œ (ì¥ê¸° ì •í™•ë„)
        recent_history = history[-50:]
        target_samples = 50

    # Limit í•™ìŠµ (í† í° ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
    learned_input_limit = None
    learned_output_limit = None

    # í† í° ë°ì´í„°ê°€ ìˆëŠ” ìƒ˜í”Œë“¤ë¡œ limit ì—­ì‚°
    samples_with_tokens = [p for p in recent_history if 'token_data' in p]

    if len(samples_with_tokens) >= 3:
        # Input limit í•™ìŠµ (input + cache_creation ê¸°ì¤€)
        input_limits = []
        output_limits = []

        for point in samples_with_tokens:
            if point['actual_value'] > 0:  # 0% ì œì™¸
                tokens = point['token_data']
                input_total = tokens['input_tokens'] + tokens['cache_creation_tokens']
                output_total = tokens['output_tokens']

                # ì—­ì‚°: limit = tokens / (percentage / 100) / 300ë¶„
                input_limit_per_min = input_total / (point['actual_value'] * 300)
                output_limit_per_min = output_total / (point['actual_value'] * 300)

                input_limits.append(input_limit_per_min)
                output_limits.append(output_limit_per_min)

        if input_limits:
            # Exponential weighted average
            decay_factor = 0.85
            weights = [decay_factor ** (len(input_limits) - 1 - i) for i in range(len(input_limits))]
            total_weight = sum(weights)

            learned_input_limit = sum(l * w for l, w in zip(input_limits, weights)) / total_weight
            learned_output_limit = sum(l * w for l, w in zip(output_limits, weights)) / total_weight

    # Offset ê³„ì‚° (fallbackìš©)
    offsets = [point['offset'] for point in recent_history]

    # Exponential weighted average (ìµœê·¼ ê²ƒì¼ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ë†’ìŒ)
    weights = []
    decay_factor = 0.9
    for i in range(len(offsets)):
        weight = decay_factor ** (len(offsets) - 1 - i)  # ìµœì‹ ì¼ìˆ˜ë¡ ë†’ìŒ
        weights.append(weight)

    total_weight = sum(weights)
    weighted_offsets = [o * w for o, w in zip(offsets, weights)]
    offset_mean = sum(weighted_offsets) / total_weight

    # í‘œì¤€í¸ì°¨ ê³„ì‚°
    offset_variance = sum(((x - offset_mean) ** 2) * w for x, w in zip(offsets, weights)) / total_weight
    offset_std = offset_variance ** 0.5

    # Confidence ê³„ì‚°
    # ìƒ˜í”Œì´ ë§ê³  í‘œì¤€í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ confidence ë†’ìŒ
    sample_confidence = min(sample_count / target_samples, 1.0)
    stability_confidence = max(0.0, 1.0 - offset_std * 10)  # stdê°€ ì‘ì„ìˆ˜ë¡ ë†’ìŒ
    confidence = (sample_confidence + stability_confidence) / 2.0

    model = {
        'offset_mean': round(offset_mean, 4),
        'offset_std': round(offset_std, 4),
        'confidence': round(confidence, 2),
        'sample_count': len(history),
        'last_updated': datetime.now(ZoneInfo('Asia/Seoul')).isoformat(),
        'baseline_threshold': BASELINE_THRESHOLD,
        'status': 'learning' if confidence < 0.7 else 'learned',
        'recent_samples': len(recent_history),
        'window_key': window_key,
        'learned_input_limit': round(learned_input_limit, 0) if learned_input_limit else None,
        'learned_output_limit': round(learned_output_limit, 0) if learned_output_limit else None,
        'has_limit_learning': learned_input_limit is not None
    }

    data[window_key]['model'] = model
    save_calibration_data(data)

    return model


def get_calibrated_value(monitor_value: float, window_key: str) -> Dict:
    """
    ë³´ì •ëœ ê°’ ë°˜í™˜ (Override ìµœìš°ì„ , ì„¸ì…˜ë³„)

    Args:
        monitor_value: ëª¨ë‹ˆí„° ì½ì€ ê°’ (0.0 ~ 1.0)
        window_key: ì„¸ì…˜ ìœˆë„ìš° í‚¤

    Returns:
        dict: ë³´ì • ì •ë³´
    """
    data = load_calibration_data()

    # 1. Override í™•ì¸ (ìµœìš°ì„ )
    if window_key in data and 'latest_override' in data[window_key]:
        override = data[window_key]['latest_override']
        expires_at = datetime.fromisoformat(override['expires_at'])
        now = datetime.now(ZoneInfo('Asia/Seoul'))

        # Override ìœ íš¨ì„± ê²€ì¦
        is_valid = False

        # ì„¸ì…˜ ìœˆë„ìš°ì¸ ê²½ìš° - í˜„ì¬ ìœˆë„ìš°ì™€ ì¼ì¹˜í•´ì•¼ í•¨
        if window_key != "weekly":
            current_window = get_session_window_key(now)
            if current_window == window_key and now < expires_at:
                is_valid = True
            elif current_window != window_key:
                # ë‹¤ë¥¸ ìœˆë„ìš°ì˜ override â†’ ì‚­ì œ
                del data[window_key]['latest_override']
                save_calibration_data(data)
        else:
            # ì£¼ê°„ì€ ì‹œê°„ë§Œ ì²´í¬
            if now < expires_at:
                is_valid = True

        # Overrideê°€ ìœ íš¨í•˜ë©´ ì ìš©
        if is_valid:
            learned_limit = override.get('learned_limit')

            # Learned limit ìœ íš¨ì„± ê²€ì¦
            if learned_limit and learned_limit > 0:
                if learned_limit < MIN_LEARNED_LIMIT or learned_limit > MAX_LEARNED_LIMIT:
                    # ë²”ìœ„ ë²—ì–´ë‚˜ë©´ fallbackë¡œ ì²˜ë¦¬
                    learned_limit = None

            if learned_limit and learned_limit > 0:
                # Learned limitì´ ìˆìœ¼ë©´ ì‹¤ì‹œê°„ í† í° ê³„ì‚°
                try:
                    output_file = Path.home() / '.claude_usage.json'
                    with open(output_file, 'r') as f:
                        usage_data = json.load(f)

                    # ìœˆë„ìš°ì— ë”°ë¼ í† í° ë°ì´í„° ì„ íƒ
                    if window_key == "weekly":
                        # ì£¼ê°„ ì‚¬ìš©ëŸ‰
                        input_total = usage_data['weekly']['usage']['input_tokens'] + \
                                      usage_data['weekly']['usage']['cache_creation_tokens']
                        output_total = usage_data['weekly']['usage']['output_tokens']
                        window_minutes = 7 * 24 * 60  # 7ì¼
                    else:
                        # ì„¸ì…˜ ì‚¬ìš©ëŸ‰
                        input_total = usage_data['session']['usage']['input_tokens'] + \
                                      usage_data['session']['usage']['cache_creation_tokens']
                        output_total = usage_data['session']['usage']['output_tokens']
                        window_minutes = 300  # 5ì‹œê°„

                    # Learned limitìœ¼ë¡œ percentage ê³„ì‚° (output ê¸°ì¤€)
                    calibrated_pct = (output_total / (learned_limit * window_minutes)) * 100
                    calibrated_value = calibrated_pct / 100.0
                    method = 'override_limit_based'
                except Exception as e:
                    # ì‹¤íŒ¨ì‹œ ê³ ì •ê°’ ì‚¬ìš©
                    calibrated_value = override['calibrated_percentage'] / 100
                    method = 'override_fixed'
            else:
                # Learned limit ì—†ìœ¼ë©´ ê³ ì •ê°’ ì‚¬ìš©
                calibrated_value = override['calibrated_percentage'] / 100
                method = 'override_fixed'

            return {
                'original_value': round(monitor_value, 4),
                'calibrated_value': round(calibrated_value, 4),
                'offset_applied': round(calibrated_value - monitor_value, 4),
                'confidence': 1.0,  # OverrideëŠ” 100% ì‹ ë¢°
                'status': 'override',
                'method': method,
                'threshold': BASELINE_THRESHOLD,
                'window_key': window_key,
                'expires_at': override['expires_at'],
                'learned_limit': learned_limit
            }
        elif now >= expires_at:
            # Override ë§Œë£Œë¨ â†’ ì‚­ì œ
            del data[window_key]['latest_override']
            save_calibration_data(data)

    # 2. í•´ë‹¹ ìœˆë„ìš°ì˜ ëª¨ë¸ í™•ì¸
    if window_key not in data or data[window_key]['model'] is None:
        # ëª¨ë¸ ì—†ìŒ - baseline ì‚¬ìš©
        return {
            'original_value': round(monitor_value, 4),
            'calibrated_value': round(monitor_value, 4),
            'offset_applied': 0.0,
            'confidence': 0.0,
            'status': 'no_data',
            'threshold': BASELINE_THRESHOLD,
            'window_key': window_key
        }

    model = data[window_key]['model']

    if model['sample_count'] < 3:
        # ì¶©ë¶„í•œ ë°ì´í„° ì—†ìŒ - Global fallback limit ì‹œë„
        fallback_limit = get_global_fallback_limit()

        if fallback_limit and fallback_limit > 0 and window_key != "weekly":
            # Fallback limitìœ¼ë¡œ ê³„ì‚° (ë‹¤ë¥¸ ì„¸ì…˜ì˜ í•™ìŠµ ë°ì´í„° ì‚¬ìš©)
            try:
                output_file = Path.home() / '.claude_usage.json'
                with open(output_file, 'r') as f:
                    usage_data = json.load(f)

                output_total = usage_data['session']['usage']['output_tokens']
                calibrated_pct = (output_total / (fallback_limit * 300)) * 100
                calibrated_value = calibrated_pct / 100.0

                return {
                    'original_value': round(monitor_value, 4),
                    'calibrated_value': round(calibrated_value, 4),
                    'offset_applied': round(calibrated_value - monitor_value, 4),
                    'confidence': 0.5,  # ì¤‘ê°„ ì‹ ë¢°ë„
                    'status': 'learning_with_fallback',
                    'threshold': BASELINE_THRESHOLD,
                    'window_key': window_key,
                    'method': 'fallback_limit',
                    'fallback_limit': fallback_limit
                }
            except:
                pass  # Fallback ì‹¤íŒ¨ì‹œ ì›ë³¸ê°’ ì‚¬ìš©

        # Fallbackë„ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ê°’ ì‚¬ìš©
        return {
            'original_value': round(monitor_value, 4),
            'calibrated_value': round(monitor_value, 4),
            'offset_applied': 0.0,
            'confidence': model['confidence'],
            'status': 'insufficient_data',
            'threshold': BASELINE_THRESHOLD,
            'window_key': window_key
        }

    # ë³´ì •ê°’ ì ìš© (3ê°œ ìƒ˜í”Œë¶€í„°)
    # Limit í•™ìŠµì´ ì™„ë£Œëœ ê²½ìš° learned limit ì‚¬ìš©, ì•„ë‹ˆë©´ offset ì‚¬ìš©
    if model.get('has_limit_learning'):
        # Limit ê¸°ë°˜ ì˜ˆì¸¡ (ë” ì •í™•í•¨)
        # í˜„ì¬ í† í° ì‚¬ìš©ëŸ‰ ì½ê¸°
        try:
            output_file = Path.home() / '.claude_usage.json'
            with open(output_file, 'r') as f:
                data = json.load(f)

            input_total = data['session']['usage']['input_tokens'] + data['session']['usage']['cache_creation_tokens']
            output_total = data['session']['usage']['output_tokens']

            # Learned limitìœ¼ë¡œ percentage ê³„ì‚°
            input_pct = (input_total / (model['learned_input_limit'] * 300)) * 100
            output_pct = (output_total / (model['learned_output_limit'] * 300)) * 100
            calibrated_value = max(input_pct, output_pct) / 100.0

            method = 'limit_based'
        except:
            # ì‹¤íŒ¨ì‹œ offset ë°©ì‹ìœ¼ë¡œ fallback
            calibrated_value = monitor_value + model['offset_mean']
            method = 'offset_fallback'
    else:
        # Limit í•™ìŠµì´ ì—†ìŒ - Global fallback limit ì‹œë„
        fallback_limit = get_global_fallback_limit()

        if fallback_limit and fallback_limit > 0 and window_key != "weekly":
            # Fallback limitìœ¼ë¡œ ê³„ì‚° (ë‹¤ë¥¸ ì„¸ì…˜ì˜ í•™ìŠµ ë°ì´í„° ì‚¬ìš©)
            try:
                output_file = Path.home() / '.claude_usage.json'
                with open(output_file, 'r') as f:
                    usage_data = json.load(f)

                output_total = usage_data['session']['usage']['output_tokens']
                calibrated_pct = (output_total / (fallback_limit * 300)) * 100
                calibrated_value = calibrated_pct / 100.0
                method = 'fallback_limit'
            except:
                # Fallback ì‹¤íŒ¨ì‹œ offset ë°©ì‹ìœ¼ë¡œ fallback
                calibrated_value = monitor_value + model['offset_mean']
                method = 'offset_based'
        else:
            # Fallbackë„ ì—†ìœ¼ë©´ offset ê¸°ë°˜ ì˜ˆì¸¡
            calibrated_value = monitor_value + model['offset_mean']
            method = 'offset_based'
            fallback_limit = None

    threshold = BASELINE_THRESHOLD * (1.0 + model['confidence'] * 0.5)

    return {
        'original_value': round(monitor_value, 4),
        'calibrated_value': round(calibrated_value, 4),
        'offset_applied': round(model['offset_mean'], 4),
        'confidence': model['confidence'],
        'status': model['status'],
        'threshold': round(threshold, 4),
        'window_key': window_key,
        'method': method,
        'learned_limits': {
            'input': model.get('learned_input_limit'),
            'output': model.get('learned_output_limit')
        } if model.get('has_limit_learning') else None
    }


def prompt_for_actual_usage(session_monitor: float, weekly_monitor: float, window_key: str) -> Optional[Tuple[float, Optional[float]]]:
    """
    ì‚¬ìš©ìì—ê²Œ ì‹¤ì œ ì‚¬ìš©ëŸ‰ ì…ë ¥ ìš”ì²­ (ì„¸ì…˜ + ì£¼ê°„)

    Args:
        session_monitor: ì„¸ì…˜ ëª¨ë‹ˆí„° ê°’ (0.0 ~ 1.0)
        weekly_monitor: ì£¼ê°„ ëª¨ë‹ˆí„° ê°’ (0.0 ~ 1.0)
        window_key: ì„¸ì…˜ ìœˆë„ìš° í‚¤

    Returns:
        tuple: (session_actual, weekly_actual or None), ì·¨ì†Œì‹œ None
    """
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Calibration Check for {window_key}")
        print(f"{'='*60}")
        print(f"Monitor Session: {session_monitor*100:.1f}%")
        print(f"Monitor Weekly:  {weekly_monitor*100:.1f}%")
        print(f"\nPlease check 'claude usage' and enter:")
        print(f"  Session Output: XX%")
        print(f"  Weekly Output:  XX%")
        print(f"\nPress Enter on Session to skip all.\n")

        # ì„¸ì…˜ ì…ë ¥
        session_input = input("Actual Session Output %: ").strip()
        if not session_input or session_input.lower() in ['skip', 's', 'cancel', 'q']:
            return None

        session_input = session_input.replace('%', '').strip()
        session_actual = float(session_input)

        if session_actual < 0 or session_actual > 100:
            print(f"âš ï¸  Invalid: {session_actual}%")
            return None

        # ì£¼ê°„ ì…ë ¥ (ì„ íƒì‚¬í•­)
        weekly_input = input("Actual Weekly Output % (Enter to skip): ").strip()
        if not weekly_input:
            print("â­ï¸  Weekly skipped")
            return (session_actual / 100.0, None)

        weekly_input = weekly_input.replace('%', '').strip()
        weekly_actual = float(weekly_input)

        if weekly_actual < 0 or weekly_actual > 100:
            print(f"âš ï¸  Invalid weekly: {weekly_actual}%")
            return (session_actual / 100.0, None)

        return (session_actual / 100.0, weekly_actual / 100.0)

    except ValueError:
        print(f"âš ï¸  Invalid input")
        return None
    except (EOFError, KeyboardInterrupt):
        return None
    except Exception as e:
        print(f"âš ï¸  Error: {e}")
        return None


def auto_calibrate_with_prompt() -> Optional[Dict]:
    """
    ìë™ ë³´ì • (ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸ í¬í•¨)

    ëª¨ë‹ˆí„°ì—ì„œ ê°’ ì½ê³  â†’ ì‚¬ìš©ìì—ê²Œ ì‹¤ì œ ê°’ ë¬¼ì–´ë³´ê³  â†’ ê¸°ë¡

    Returns:
        dict: ê²°ê³¼ ì •ë³´, ì‹¤íŒ¨ì‹œ None
    """
    # 1. ëª¨ë‹ˆí„° ê°’ ì½ê¸°
    monitor_data = get_monitor_reading()
    if monitor_data is None:
        print("âš ï¸  No active monitor data")
        return None

    session_monitor, weekly_monitor, window_key, token_data = monitor_data

    # 2. ì‚¬ìš©ìì—ê²Œ ì‹¤ì œ ê°’ ë¬¼ì–´ë³´ê¸°
    actual_values = prompt_for_actual_usage(session_monitor, weekly_monitor, window_key)
    if actual_values is None:
        print("â­ï¸  Calibration skipped")
        return None

    session_actual, weekly_actual = actual_values

    # 3. ë³´ì • í¬ì¸íŠ¸ ê¸°ë¡ (í† í° ë°ì´í„° í¬í•¨)
    point = record_calibration_point(window_key, session_monitor, session_actual, token_data)

    # 4. ëª¨ë¸ ì—…ë°ì´íŠ¸
    model = update_calibration_model(window_key)

    # 5. ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… Calibration recorded for {window_key}:")
    print(f"   Session Monitor: {session_monitor*100:.1f}%")
    print(f"   Session Actual:  {session_actual*100:.1f}%")
    print(f"   Offset:  {point['offset']*100:+.1f}%")
    print(f"   Samples: {model['sample_count']}")
    print(f"   Confidence: {model['confidence']:.2f} ({model['status']})")

    if weekly_actual is not None:
        weekly_offset = weekly_actual - weekly_monitor
        print(f"\n   Weekly Monitor: {weekly_monitor*100:.1f}%")
        print(f"   Weekly Actual:  {weekly_actual*100:.1f}%")
        print(f"   Weekly Offset:  {weekly_offset*100:+.1f}%")

    if model['sample_count'] < 10:
        remaining = 10 - model['sample_count']
        print(f"\n   â³ Need {remaining} more samples for {window_key}")
    elif model['status'] == 'learning':
        print(f"\n   ğŸ“š Learning in progress...")
    else:
        print(f"\n   âœ… Model ready for {window_key}!")

    return {
        'status': 'success',
        'window_key': window_key,
        'point': point,
        'model': model
    }


def show_status():
    """ì „ì²´ ë³´ì • ìƒíƒœ ì¶œë ¥"""
    data = load_calibration_data()

    if not data:
        print("No calibration data yet.")
        return

    print(f"\n{'='*60}")
    print("Calibration Status by Session Window")
    print(f"{'='*60}\n")

    for window_key in sorted(data.keys()):
        window_data = data[window_key]
        model = window_data.get('model')
        history_count = len(window_data.get('history', []))

        print(f"ğŸ“Š {window_key}")
        print(f"   Samples: {history_count}")

        if model:
            print(f"   Offset: {model['offset_mean']*100:+.2f}%")
            print(f"   Confidence: {model['confidence']:.2f}")
            print(f"   Status: {model['status']}")
        else:
            print(f"   Status: No model yet")

        print()


def calibrate_with_args(session_actual: float, weekly_actual: Optional[float] = None) -> Optional[Dict]:
    """
    ì»¤ë§¨ë“œ ì¸ìë¡œ ë³´ì • ìˆ˜í–‰ (ì¦‰ì‹œ ë°˜ì˜ + í† í° ì—­ì‚°)

    Args:
        session_actual: ì‹¤ì œ ì„¸ì…˜ ì‚¬ìš©ëŸ‰ (0-100)
        weekly_actual: ì‹¤ì œ ì£¼ê°„ ì‚¬ìš©ëŸ‰ (0-100, optional)

    Returns:
        dict: ê²°ê³¼ ì •ë³´, ì‹¤íŒ¨ì‹œ None
    """
    # 1. ëª¨ë‹ˆí„° ê°’ ì½ê¸°
    monitor_data = get_monitor_reading()
    if monitor_data is None:
        print("âš ï¸  No active monitor data")
        return None

    session_monitor, weekly_monitor, window_key, token_data = monitor_data

    # 2. ê°’ ê²€ì¦
    if session_actual < 0 or session_actual > 100:
        print(f"âš ï¸  Invalid session value: {session_actual}%")
        return None

    if weekly_actual is not None and (weekly_actual < 0 or weekly_actual > 100):
        print(f"âš ï¸  Invalid weekly value: {weekly_actual}%")
        return None

    # 3. ì„¸ì…˜ í† í° ì—­ì‚°ìœ¼ë¡œ limit ê³„ì‚°
    session_window_minutes = 300  # 5ì‹œê°„

    input_total = token_data['input_tokens'] + token_data['cache_creation_tokens']
    output_total = token_data['output_tokens']

    learned_input_limit = reverse_calculate_limit(session_actual, input_total, session_window_minutes)
    learned_output_limit = reverse_calculate_limit(session_actual, output_total, session_window_minutes)

    # 4. ë³´ì • í¬ì¸íŠ¸ ê¸°ë¡ (í† í° ë°ì´í„° í¬í•¨, í•™ìŠµìš©)
    session_actual_normalized = session_actual / 100.0
    point = record_calibration_point(window_key, session_monitor, session_actual_normalized, token_data)

    # 5. ì„¸ì…˜ Override ì„¤ì • (ì¦‰ì‹œ ë°˜ì˜, output_limit ì‚¬ìš©)
    window_end = get_window_end_time(window_key)
    set_calibration_override(
        window_key,
        session_actual,
        learned_output_limit or 0,  # Output limitë§Œ ì‚¬ìš©
        window_end.isoformat()
    )

    # 6. ëª¨ë¸ ì—…ë°ì´íŠ¸ (í•™ìŠµìš©)
    model = update_calibration_model(window_key)

    # 7. ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… ì¦‰ì‹œ ë°˜ì˜: {session_actual:.1f}% â†’ SwiftBarì— í‘œì‹œë¨")
    print(f"\nğŸ“Š Session Calibration for {window_key}:")
    print(f"   Monitor: {session_monitor*100:.1f}%")
    print(f"   Actual:  {session_actual:.1f}%")
    print(f"   Offset:  {point['offset']*100:+.1f}%")

    print(f"\nğŸ¯ í•™ìŠµëœ Limit:")
    if learned_input_limit:
        print(f"   Input:  {learned_input_limit:,} TPM")
    if learned_output_limit:
        print(f"   Output: {learned_output_limit:,} TPM")

    print(f"\nâ° Override:")
    print(f"   ë§Œë£Œ ì‹œê°„: {window_end.strftime('%H:%M')} ({window_end.strftime('%Y-%m-%d')})")
    print(f"   ìƒíƒœ: ì„¸ì…˜ ëë‚  ë•Œê¹Œì§€ {session_actual:.1f}% ê³ ì • í‘œì‹œ")

    print(f"\nğŸ“š íˆìŠ¤í† ë¦¬:")
    print(f"   ìƒ˜í”Œ ìˆ˜: {model['sample_count']}ê°œ")
    print(f"   ì‹ ë¢°ë„: {model['confidence']:.2f}")
    print(f"   ìƒíƒœ: {model['status']}")

    result = {
        'status': 'success',
        'override': True,
        'session': {
            'calibrated_percentage': session_actual,
            'learned_limits': {
                'input': learned_input_limit,
                'output': learned_output_limit
            },
            'window_key': window_key,
            'expires_at': window_end.isoformat(),
            'point': point,
            'model': model
        }
    }

    # 8. ì£¼ê°„ ì‚¬ìš©ëŸ‰ ì²˜ë¦¬
    if weekly_actual is not None:
        weekly_window_key = get_weekly_window_key()
        weekly_window_minutes = 7 * 24 * 60  # 7ì¼ = 10080ë¶„

        # ì£¼ê°„ í† í°ìœ¼ë¡œ limit ì—­ì‚° (ì£¼ê°„ í† í° ë°ì´í„°ëŠ” ë³„ë„ë¡œ ì½ì–´ì•¼ í•¨)
        # í˜„ì¬ëŠ” ì„¸ì…˜ í† í°ê³¼ ë™ì¼í•˜ê²Œ ì‚¬ìš© (ì‹¤ì œë¡œëŠ” weekly usage ë°ì´í„° í•„ìš”)
        try:
            output_file = Path.home() / '.claude_usage.json'
            with open(output_file, 'r') as f:
                usage_data = json.load(f)

            weekly_input_total = usage_data['weekly']['usage']['input_tokens'] + \
                                 usage_data['weekly']['usage']['cache_creation_tokens']
            weekly_output_total = usage_data['weekly']['usage']['output_tokens']

            weekly_learned_input_limit = reverse_calculate_limit(weekly_actual, weekly_input_total, weekly_window_minutes)
            weekly_learned_output_limit = reverse_calculate_limit(weekly_actual, weekly_output_total, weekly_window_minutes)

            # ì£¼ê°„ Override ì„¤ì •
            weekly_window_end = get_window_end_time(weekly_window_key)
            set_calibration_override(
                weekly_window_key,
                weekly_actual,
                weekly_learned_output_limit or 0,  # Output limitë§Œ ì‚¬ìš©
                weekly_window_end.isoformat()
            )

            weekly_offset = (weekly_actual / 100.0) - weekly_monitor
            print(f"\nğŸ“Š Weekly Calibration:")
            print(f"   Monitor: {weekly_monitor*100:.1f}%")
            print(f"   Actual:  {weekly_actual:.1f}%")
            print(f"   Offset:  {weekly_offset*100:+.1f}%")

            print(f"\nğŸ¯ ì£¼ê°„ í•™ìŠµëœ Limit:")
            if weekly_learned_input_limit:
                print(f"   Input:  {weekly_learned_input_limit:,} TPM")
            if weekly_learned_output_limit:
                print(f"   Output: {weekly_learned_output_limit:,} TPM")

            print(f"\nâ° ì£¼ê°„ Override:")
            print(f"   ë§Œë£Œ ì‹œê°„: {weekly_window_end.strftime('%Y-%m-%d %H:%M')}")
            print(f"   ìƒíƒœ: 7ì¼ê°„ {weekly_actual:.1f}% ê³ ì • í‘œì‹œ")

            result['weekly'] = {
                'calibrated_percentage': weekly_actual,
                'learned_limits': {
                    'input': weekly_learned_input_limit,
                    'output': weekly_learned_output_limit
                },
                'window_key': weekly_window_key,
                'expires_at': weekly_window_end.isoformat()
            }

        except Exception as e:
            print(f"\nâš ï¸  ì£¼ê°„ Override ì„¤ì • ì‹¤íŒ¨: {e}")

    return result


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description='Calibration Learner v2',
        epilog='Examples:\n'
               '  %(prog)s 2.3 35.5    # Calibrate with session and weekly\n'
               '  %(prog)s 2.3         # Calibrate with session only\n'
               '  %(prog)s --status    # Show calibration status',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('session', type=float, nargs='?',
                        help='Actual session output percentage (e.g., 2.3)')
    parser.add_argument('weekly', type=float, nargs='?',
                        help='Actual weekly output percentage (optional, e.g., 35.5)')
    parser.add_argument('--calibrate', action='store_true',
                        help='Run calibration with interactive prompt (legacy)')
    parser.add_argument('--status', action='store_true',
                        help='Show calibration status')
    parser.add_argument('--history', action='store_true',
                        help='Show calibration history (JSON)')

    args = parser.parse_args()

    if args.status:
        show_status()
    elif args.history:
        data = load_calibration_data()
        print(json.dumps(data, indent=2))
    elif args.calibrate:
        # Legacy interactive mode
        result = auto_calibrate_with_prompt()
        if result:
            print(f"\nâœ¨ Calibration complete!")
    elif args.session is not None:
        # New argument-based mode
        result = calibrate_with_args(args.session, args.weekly)
        if result:
            print(f"\nâœ¨ Calibration complete!")
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
